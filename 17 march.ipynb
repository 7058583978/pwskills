{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec27451-dd0d-4456-ba55-d28581464390",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a77b8c-a2da-4264-b7a4-64d7aa3cafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "-Missing values are data points that are not available or were not recorded for a particular variable\n",
    "or observation in a dataset. In other words, missing values refer to the absence of a value or a piece \n",
    "of information that would typically be expected to be present in a dataset.\n",
    "\n",
    "-Many machine learning algorithms fail if the dataset contains missing values. \n",
    "However, algorithms like K-nearest and Naive Bayes support data with missing values.\n",
    "You may end up building a biased machine learning model, leading to incorrect results \n",
    "if the missing values are not handled properly.\n",
    "\n",
    "1.Decision trees: Decision trees can handle missing values in the data and can still produce accurate results.\n",
    "\n",
    "2.Random forests: Random forests are an extension of decision trees and can also handle missing values in the data.\n",
    "\n",
    "3.k-Nearest Neighbors (k-NN): k-NN is a non-parametric algorithm that can handle missing values by imputing the missing values with \n",
    "the mean or median value of the k-nearest neighbors.\n",
    "\n",
    "4.Support Vector Machines (SVM): SVM can handle missing values by imputing them with the mean or median value of the available data.\n",
    "\n",
    "5.Gaussian Mixture Models (GMM): GMM can handle missing values by imputing them with the mean or median value of the available data.\n",
    "\n",
    "6.Principal Component Analysis (PCA): PCA can handle missing values by imputing them with the mean or median value of the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9ff67-c970-4882-8ef2-a3c587f133e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de52126-e424-4f46-b7f5-3edfa3258a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deletion: This involves removing the entire row or column that contains missing data. This method is simple and straightforward, \n",
    "but it can lead to loss of important information and may affect the accuracy of the analysis.\n",
    "\n",
    "Imputation: Imputation involves filling in missing values with estimated or imputed values. \n",
    "There are several methods for imputation, such as mean imputation, median imputation, regression imputation, \n",
    "and k-nearest neighbor imputation. The imputation method chosen will depend on the type and amount of missing data,\n",
    "as well as the distribution of the data.\n",
    "\n",
    "Marking: In this method, missing values are replaced with a special value, such as -999 or NaN, to indicate that the value is missing. \n",
    "This method can be useful in cases where imputation is not possible or not desirable.\n",
    "\n",
    "Model-based imputation: This method involves creating a model to predict the missing values based on the available data. For example,\n",
    "regression models can be used to predict missing values based on other variables in the dataset.\n",
    "\n",
    "Multiple imputation: This involves creating multiple imputations of missing data using different imputation methods, and then combining \n",
    "the results to obtain a final estimate. This method can provide more accurate estimates than single imputation methods, but it can also\n",
    "be more computationally intensive.\n",
    "\n",
    "Machine learning-based imputation: In this method, machine learning algorithms are used to predict missing values based on other variables \n",
    "in the dataset. This method can be useful when dealing with large datasets with complex relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95565378-51fb-4abc-86d4-364361b92a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#we know there are missing values so we replace NAN values with mean mode ans median\n",
    "df = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f4baa1f-832f-4b99-b01f-69c86fc69a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age_mean\"]=df[\"age\"].fillna(df[\"age\"].mean()) #should be used when outliers are absent\n",
    "df[\"age_mean\"]=df[\"age\"].fillna(df[\"age\"].median())#used when outliers are present\n",
    "df[\"age_mean\"]=df[\"age\"].fillna(df[\"age\"].mode())#used for categorical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fb8ceb-4a9b-4bfd-8598-8158c118c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a51821-f04d-40ca-a7ed-461dadaa49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imbalanced data refers to a situation where the number of observations in each class or category \n",
    "of a binary or multiclass classification problem is not equal. In other words, one or more classes \n",
    "may have a much smaller number of observations than the other classes, which can lead to a significant imbalance in the data.\n",
    "\n",
    "If imbalanced data is not handled, it can lead to several issues, including:\n",
    "\n",
    "1.Biased model performance: Since most machine learning algorithms are designed to maximize overall accuracy, \n",
    "they tend to be biased towards the majority class in imbalanced data. As a result, the model may perform poorly \n",
    "on the minority class and may even misclassify most or all of the minority class examples.\n",
    "\n",
    "2.Poor generalization: Models trained on imbalanced data may have poor generalization performance when applied to new, \n",
    "unseen data, particularly if the distribution of classes in the new data is different from that in the training data.\n",
    "\n",
    "3.Overfitting: Imbalanced data can also lead to overfitting, where the model learns to memorize the training data instead \n",
    "of generalizing to new data. This can happen when the model is optimized to minimize the training error without taking into\n",
    "account the imbalanced nature of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d45550-7765-4e9c-a49a-9d52ced1e91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "sampling are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc3ac4-25e8-4048-a4fa-7d1d83091bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Up-sampling and down-sampling are two common techniques used to address the issue of imbalanced data in a classification problem.\n",
    "\n",
    "1.Up-sampling involves increasing the number of instances in the minority class to balance the \n",
    "class distribution. This can be done by either duplicating existing instances in the minority\n",
    "class (simple up-sampling) or generating synthetic instances that are similar to the existing ones \n",
    "(e.g., using techniques like SMOTE - Synthetic Minority Over-sampling Technique). Up-sampling can help \n",
    "to ensure that the minority class is well-represented in the dataset and can improve the performance of machine learning models.\n",
    "\n",
    "2.Down-sampling, on the other hand, involves reducing the number of instances in the majority class to balance the class distribution.\n",
    "This can be done by either randomly selecting a subset of instances in the majority class (simple down-sampling) or selecting instances\n",
    "that are similar to those in the minority class (e.g., using techniques like Tomek links). Down-sampling can help to prevent the machine\n",
    "learning models from being biased towards the majority class, and can improve the performance on the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07fd8428-cef9-44f4-8480-e0a70a6dbe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc8e62b3-88f5-41ad-b601-4adca6a639c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "n_samples = 100\n",
    "class_0_ratio = 0.8\n",
    "n_class_0 = int(n_samples * class_0_ratio)\n",
    "n_class_1 = n_samples - n_class_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7439100-904d-4e48-b032-574e181c0802",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = pd.DataFrame({\n",
    "    'first': np.random.normal(loc=0, scale=1, size=n_class_0),\n",
    "    'second': np.random.normal(loc=0, scale=1, size=n_class_0),\n",
    "    'third': [0] * n_class_0\n",
    "})\n",
    "\n",
    "class_1 = pd.DataFrame({\n",
    "    'first': np.random.normal(loc=2, scale=1, size=n_class_1),\n",
    "    'second': np.random.normal(loc=2, scale=1, size=n_class_1),\n",
    "    'third': [1] * n_class_1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a605c57d-c360-4c76-8a47-d8c15546272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([class_0,class_1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cdedb00-7d40-487e-b68e-2946652b5bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority=df[df['third']==1]\n",
    "df_majority=df[df['third']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a49e46f-252b-412f-8085-b2c5a6cdbb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3991ad54-4a5a-461b-b0db-aa8fc51ddfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority_upsample=resample(df_minority,\n",
    "                             replace=True,\n",
    "                             n_samples=len(df_majority))\n",
    "\n",
    "df_majority_downsample=resample(df_majority,\n",
    "                             replace=False, \n",
    "                              n_samples=len(df_minority))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf777a1-1992-468e-ae35-f610484fc978",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f204650-3ff1-4603-b752-23b7ce2a525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data augmentation is a technique used to increase the size of a dataset by creating new,\n",
    "synthetic samples based on the existing ones. The aim of data augmentation is to improve the performance \n",
    "and robustness of machine learning models by providing more diverse and representative examples for training.\n",
    "\n",
    "One popular data augmentation technique is SMOTE (Synthetic Minority Over-sampling Technique). \n",
    "SMOTE is used in cases where the dataset is imbalanced, meaning that one class has significantly \n",
    "fewer examples than the other(s). SMOTE generates synthetic examples for the minority class by\n",
    "interpolating between existing examples of the minority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a67a8-0745-4df9-957d-6aaa91202102",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051bd9f-07bd-45e6-9107-7595e0b9929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Outliers are data points in a dataset that are significantly different from the other data points.\n",
    "Outliers can be caused by a variety of factors, such as measurement errors, experimental errors, or rare events. \n",
    "Outliers can have a significant impact on the statistical analysis of the dataset and can lead to incorrect conclusions.\n",
    "\n",
    "It is essential to handle outliers for several reasons:\n",
    "\n",
    "1.They can bias statistical analysis: Outliers can significantly affect the mean and standard deviation of the dataset,\n",
    "which can lead to incorrect statistical analysis. For example, if the mean is significantly affected by an outlier,\n",
    "it may not be a representative measure of the central tendency of the data.\n",
    "\n",
    "2.They can affect machine learning algorithms: Outliers can also affect the performance of machine learning algorithms \n",
    "by distorting the relationships between the features and the target variable. This can lead to overfitting, where the model\n",
    "fits the noise instead of the underlying patterns in the data.\n",
    "\n",
    "3.They can affect data visualization: Outliers can also affect data visualization by distorting the scales of the plots,\n",
    "making it difficult to see the patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b20cbf-e1e9-4185-aada-a23c65657586",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6e4cb-ed12-4a36-8c0f-8b465615a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deletion: This involves removing the entire row or column that contains missing data. This method is simple and straightforward, \n",
    "but it can lead to loss of important information and may affect the accuracy of the analysis.\n",
    "\n",
    "Imputation: Imputation involves filling in missing values with estimated or imputed values. \n",
    "There are several methods for imputation, such as mean imputation, median imputation, regression imputation, \n",
    "and k-nearest neighbor imputation. The imputation method chosen will depend on the type and amount of missing data,\n",
    "as well as the distribution of the data.\n",
    "\n",
    "Marking: In this method, missing values are replaced with a special value, such as -999 or NaN, to indicate that the value is missing. \n",
    "This method can be useful in cases where imputation is not possible or not desirable.\n",
    "\n",
    "Model-based imputation: This method involves creating a model to predict the missing values based on the available data. For example,\n",
    "regression models can be used to predict missing values based on other variables in the dataset.\n",
    "\n",
    "Multiple imputation: This involves creating multiple imputations of missing data using different imputation methods, and then combining \n",
    "the results to obtain a final estimate. This method can provide more accurate estimates than single imputation methods, but it can also\n",
    "be more computationally intensive.\n",
    "\n",
    "Machine learning-based imputation: In this method, machine learning algorithms are used to predict missing values based on other variables \n",
    "in the dataset. This method can be useful when dealing with large datasets with complex relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152e168-bc78-4ece-b4dd-d8f361852270",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef81fea-d261-4341-bd52-552818c8c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "When dealing with missing data, it is important to determine whether the data is missing at random (MAR) or not at random (MNAR). \n",
    "Here are some strategies that can be used to determine the missing data pattern:\n",
    "\n",
    "Check the missing data pattern: Visualize the pattern of missing data to see if there is a specific pattern or not.\n",
    "If the missing data is distributed randomly across the dataset, it is more likely to be MAR. However, if there is a \n",
    "particular pattern (e.g., missing values only for certain categories or time periods), it may be MNAR.\n",
    "\n",
    "Explore correlation between missing data and other variables: Examine whether the missing data is correlated with other variables in the dataset.\n",
    "If there is no correlation, the missing data is more likely to be MAR. However, if the missing data is related to other variables, it may be MNAR.\n",
    "\n",
    "Impute the missing values: By imputing the missing data, we can compare the imputed values with the actual values to determine the missing data\n",
    "pattern. If the imputed values are similar to the actual values, the missing data is more likely to be MAR. If the imputed values differ \n",
    "significantly from the actual values, it may be MNAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da114f4-55c5-43cf-b73e-6f9df9a40fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f9133-e18f-46eb-94ee-67e5430f0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imbalanced datasets, where the proportion of samples in each class is unequal, are common in many machine learning applications, \n",
    "including medical diagnosis. Here are some strategies that can be used to evaluate the performance of machine learning models on imbalanced datasets:\n",
    "    \n",
    "Resample the dataset: One common approach to address class imbalance is to resample the dataset.\n",
    "Two common techniques for resampling include oversampling the minority class and undersampling the majority class.\n",
    "Oversampling involves generating more samples for the minority class, while undersampling involves removing samples from the majority class.\n",
    "However, its important to ensure that the resampling technique does not introduce bias into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd5dfaf-ca3a-411f-b61b-3ef71d8c8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe07598-3310-44ba-95c6-17b5d80e4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random undersampling: This method randomly selects a subset of samples from the majority class to match the number of samples in the minority class.\n",
    "\n",
    "1.Cluster centroids: This method clusters the majority class samples and then selects the centroids of each cluster as representatives of the \n",
    "majority class.\n",
    "\n",
    "2.Tomek links: Tomek links are pairs of samples from different classes that are closest to each other. This method removes the majority class \n",
    "samples that are part of Tomek links.\n",
    "\n",
    "3.NearMiss: NearMiss is an undersampling method that selects samples from the majority class that are closest to the minority class samples.\n",
    "\n",
    "4.One-sided selection: This method selects the samples from the majority class that are nearest to the decision boundary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd7d6f-a9c7-405b-bfc3-c237042c0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054cc31-b141-4eac-9f06-1d227ad7865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "When dealing with a dataset with a low percentage of occurrences of a rare event, it's common to use upsampling methods to balance the dataset.\n",
    "Here are some methods that can be employed to up-sample the minority class:\n",
    "\n",
    "1.Random oversampling: This method randomly duplicates samples from the minority class to increase their number and balance the dataset.\n",
    "\n",
    "2.SMOTE: Synthetic Minority Over-sampling Technique (SMOTE) generates new synthetic samples by interpolating between the minority class samples. \n",
    "This method avoids exact replication of minority samples and provides more variety to the dataset.\n",
    "\n",
    "3.ADASYN: Adaptive Synthetic Sampling (ADASYN) generates synthetic samples by considering the difficulty of learning samples in the minority class.\n",
    "This method creates more synthetic samples for difficult to learn samples and less for easy to learn samples.\n",
    "\n",
    "4.Synthetic Minority Over-sampling TEchnique with Application of Multi-grained Architecture (SMOTEMA): \n",
    "SMOTEMA is an enhanced version of SMOTE which generates synthetic samples in a multi-grained way. \n",
    "This method generates samples with different magnitudes of changes from the original samples.\n",
    "\n",
    "5.Class weighting: Class weighting assigns higher weights to the minority class samples during model training to increase their \n",
    "influence on the learning process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
